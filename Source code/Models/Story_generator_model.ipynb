{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP PROJECT Story generator model",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install gpt-2-simple\n",
        "# #!pip install tensorflow==1.15\n",
        "# %tensorflow_version 1.x\n",
        "# !pip install flask-ngrok\n",
        "!pip install gpt-2-simple\n",
        "!pip install language_tool_python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWevpUx5S2f4",
        "outputId": "766b4d80-4a99-44f4-c744-8687f0fe6e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gpt-2-simple in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (4.64.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: tensorflow>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.24.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.44.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.17.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (4.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.0.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (13.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.1.2)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.5.1->gpt-2-simple) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.5.1->gpt-2-simple) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple) (3.2.0)\n",
            "Collecting language_tool_python\n",
            "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from language_tool_python) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from language_tool_python) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->language_tool_python) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->language_tool_python) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->language_tool_python) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->language_tool_python) (1.24.3)\n",
            "Installing collected packages: language-tool-python\n",
            "Successfully installed language-tool-python-2.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gpt_2_simple as gpt2_simple\n",
        "import threading\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import requests \n",
        "import language_tool_python\n",
        "tool = language_tool_python.LanguageTool('en-US')"
      ],
      "metadata": {
        "id": "FSalPcQMS7xS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01f45e6-2159-41bf-cff2-0c5f55853650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading LanguageTool 5.7: 100%|██████████| 225M/225M [00:11<00:00, 18.8MB/s]\n",
            "Unzipping /tmp/tmp87f7vos1.zip to /root/.cache/language_tool_python.\n",
            "Downloaded https://www.languagetool.org/download/LanguageTool-5.7.zip to /root/.cache/language_tool_python.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_simple.download_gpt2(model_name='124M')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mowguVmTTAhF",
        "outputId": "1bb914fc-6142-4f3f-97f8-87bfbea89685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 619Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:01, 570kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 776Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [01:23, 5.96Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 762Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:01, 865kit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:01, 862kit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "gpt2_simple.mount_gdrive()"
      ],
      "metadata": {
        "id": "Ijnp2NviTEBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2_simple.start_tf_sess()"
      ],
      "metadata": {
        "id": "Hm2dJ9IETMrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " gpt2_simple.finetune(sess, dataset=\"/content/drive/MyDrive/NLP project/Text Corpus/scary.txt\", steps=1000, model_name='124M',\n",
        " sample_every=200, save_every=1000, print_every=10, restore_from='fresh')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TRJ9kxQTRlw",
        "outputId": "7e031ee5-d9bd-4afe-baf1-c571fbafb1bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Restoring parameters from models/124M/model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 16966 tokens\n",
            "Training...\n",
            "[10 | 18.84] loss=2.00 avg=2.00\n",
            "[20 | 33.01] loss=1.94 avg=1.97\n",
            "[30 | 47.17] loss=1.82 avg=1.92\n",
            "[40 | 61.33] loss=1.07 avg=1.70\n",
            "[50 | 75.51] loss=1.06 avg=1.57\n",
            "[60 | 89.67] loss=0.56 avg=1.40\n",
            "[70 | 103.83] loss=0.36 avg=1.25\n",
            "[80 | 117.98] loss=0.29 avg=1.12\n",
            "[90 | 132.14] loss=0.16 avg=1.01\n",
            "[100 | 146.30] loss=0.09 avg=0.91\n",
            "[110 | 160.45] loss=0.10 avg=0.84\n",
            "[120 | 174.61] loss=0.07 avg=0.77\n",
            "[130 | 188.77] loss=0.07 avg=0.71\n",
            "[140 | 202.93] loss=0.05 avg=0.66\n",
            "[150 | 217.08] loss=0.06 avg=0.62\n",
            "[160 | 231.24] loss=0.04 avg=0.58\n",
            "[170 | 245.40] loss=0.05 avg=0.55\n",
            "[180 | 259.56] loss=0.05 avg=0.52\n",
            "[190 | 273.72] loss=0.04 avg=0.49\n",
            "[200 | 287.88] loss=0.04 avg=0.46\n",
            "======== SAMPLE 1 ========\n",
            "-ten-ten?\" \n",
            "\n",
            "\n",
            "\"A trawler's hat,\" the widow said. \"What do you want?\" \n",
            "\n",
            "\n",
            "The trawler let loose, and the woman and her daughter \n",
            "died in the river at the same time. Everyone was dead except \n",
            "the widow and the daughter. She had been shot \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "and had burns and scrapes all over her \n",
            "body. \n",
            "\n",
            "\n",
            "The old woman and her child ran away as fast as \n",
            "they could. Soon they came across the haunt. The woman \n",
            "was so frightened she forgot where she had been \n",
            "and went so where. \n",
            "\n",
            "\n",
            "When she finally got to the house, the haunt woman \n",
            "lay down on her haunches. With her dead head in her \n",
            "corner, she sobbed, \"I'll \n",
            "stay here forever.\" \n",
            "\n",
            "\n",
            "The haunt woman took one look and stood up. With \n",
            "and — straight out the mouth! — a gruesome, hungry ooze ! \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "THE DEAD MAN'S \n",
            "BRAINS \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "This scary story is a scary game that people play at Hal- \n",
            "lowe'en. But it can be played whenever the spirit moves \n",
            "you. \n",
            "\n",
            "\n",
            "The players sit in a circle in a darkened room and \n",
            "listen to a storyteller describe the rotting remains of a \n",
            "corpse. Each part is passed around for them to feel. \n",
            "\n",
            "\n",
            "In one version, a player is out if he or she screams \n",
            "or gasps with surprise at any one thing. In another version \n",
            "there is only fear, and each part is passed on as little \n",
            "as possible. \n",
            "\n",
            "\n",
            "Here is the story: \n",
            "\n",
            "\n",
            "Once in this town there lived a man named Brown. \n",
            "It was years ago, on this night, that he was murdered \n",
            "out of spite. \n",
            "\n",
            "\n",
            "We have here his remains. \n",
            "\n",
            "\n",
            "First, let's feel his brains. (A wet, squishy tomato) \n",
            "\n",
            "\n",
            "Now here are his eyes, still frozen with surprise. (Two \n",
            "peeled grapes) \n",
            "\n",
            "\n",
            "This is his nose. (A chicken bone) \n",
            "\n",
            "\n",
            "Here is his ear. (A dried apricot) \n",
            "\n",
            "\n",
            "And here is his hand, rotting flesh and bone. (A cloth \n",
            "or rubber glove filled with mud or ice) \n",
            "\n",
            "\n",
            "But his hair still grows. (A handful of corn silk or \n",
            "wet fur or yarn) \n",
            "\n",
            "\n",
            "And his heart still beats, now and then. (A piece of \n",
            "raw liver) \n",
            "\n",
            "\n",
            "And his blood still flows. Dip your fingers in it. It's \n",
            "nice and warm. (A bowl of catsup thinned with warm \n",
            "water) \n",
            "\n",
            "\n",
            "That's all there is, except for these worms. They are \n",
            "the ones that ate the rest of him. (A handful of wet, \n",
            "cooked spaghetti noodles) \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "• \"MAY I CARRY \n",
            "YOUR BASKET?\" • \n",
            "\n",
            "\n",
            "Sam Lewis spent the evening playing chess at his friend's \n",
            "house. It was about midnight when they finished their \n",
            "game, and he started home. Outside it was icy cold and \n",
            "as quiet as the grave. \n",
            "\n",
            "\n",
            "As he came around a turn in the road, he was surprised \n",
            "to see a woman walking ahead of him. She was carrying \n",
            "a basket covered with a white cloth. When he caught \n",
            "up to her, he looked to see who it was. But she was so \n",
            "bundled up against the cold, it was hard to see her face. \n",
            "\n",
            "\n",
            "\"Good evening,\" Sam said. \"What is it?\" \n",
            "\n",
            "\n",
            "But she didn't tell him anything. \n",
            "\n",
            "\n",
            "So he went over and laid the basket on the center \n",
            "of the road, and she followed behind. Soon they came to a house \n",
            "that was very near the house. On a bench stood a young woman \n",
            "with a bucket. On the top of the bucket was a small \n",
            "pile of ashes. \n",
            "\n",
            "\n",
            "Sam sat watching the ashes fall. Soon they \n",
            "dried up and down like candy. One had fallen in \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "it, and the other had not. \n",
            "\n",
            "\n",
            "Sam said, \"Why don't you all get a good look- \n",
            "or feel something \n",
            "of yourself.\" The young woman turned to Sam, and \n",
            "he said, \"Would you like to come out and do that?\" \n",
            "\n",
            "\n",
            "She went on to the next room and sat down next to \n",
            "her. In that room sat a young brute named Brown. \n",
            "\n",
            "\n",
            "It was about midnight Tuesday evening. Sam was sitting \n",
            "in the chair next to her, and he was sitting right next\n",
            "\n",
            "[210 | 311.74] loss=0.04 avg=0.44\n",
            "[220 | 325.89] loss=0.04 avg=0.42\n",
            "[230 | 340.05] loss=0.04 avg=0.40\n",
            "[240 | 354.21] loss=0.04 avg=0.39\n",
            "[250 | 368.37] loss=0.04 avg=0.37\n",
            "[260 | 382.54] loss=0.03 avg=0.36\n",
            "[270 | 396.70] loss=0.03 avg=0.34\n",
            "[280 | 410.87] loss=0.02 avg=0.33\n",
            "[290 | 425.02] loss=0.04 avg=0.32\n",
            "[300 | 439.18] loss=0.03 avg=0.31\n",
            "[310 | 453.33] loss=0.04 avg=0.30\n",
            "[320 | 467.49] loss=0.03 avg=0.29\n",
            "[330 | 481.64] loss=0.03 avg=0.28\n",
            "[340 | 495.80] loss=0.03 avg=0.27\n",
            "[350 | 509.95] loss=0.03 avg=0.26\n",
            "[360 | 524.11] loss=0.03 avg=0.25\n",
            "[370 | 538.26] loss=0.03 avg=0.25\n",
            "[380 | 552.41] loss=0.03 avg=0.24\n",
            "[390 | 566.57] loss=0.02 avg=0.23\n",
            "[400 | 580.72] loss=0.03 avg=0.23\n",
            "======== SAMPLE 1 ========\n",
            " in his grave. In that case the coroner found that she had been poisoned by em- \n",
            "balming fluid. \n",
            "\n",
            "\n",
            "The coroner sentenced Boonner, 47, to death. \n",
            "\n",
            "\n",
            "With the help of a \n",
            "mysterious person, he droned, \"What do you want?\" Then he \n",
            "turned his chair over, closed the window, and sat down in front of \n",
            "the fire. \n",
            "\n",
            "\n",
            "When the chair wasn't changed, he went to his room. He \n",
            "decided to take his boots off. Then he turned his seat \n",
            "to him. \"A good night's sleep is a charm,\" he \n",
            "said. \"I'll take it.\" \n",
            "\n",
            "\n",
            "As he started the car, Boonner lost his balance and fell \n",
            "to the ground. The driver of the truck grabbed him and took \n",
            "out a can of gunpowder. After that, nobody \n",
            "saw him die. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "• THE WENDIGO • \n",
            "\n",
            "\n",
            "A wealthy man wanted to go hunting in a part of north- \n",
            "ern Canada where few people had ever hunted. He trav- \n",
            "eled to a trading post and tried to find a guide to take \n",
            "him. But no one would do it. It was too dangerous, they \n",
            "said. \n",
            "\n",
            "\n",
            "Finally, he found an Indian who needed money badly, \n",
            "and he agreed to take him. The Indian's name was \n",
            "DeFago. \n",
            "\n",
            "\n",
            "They made camp in the snow near a large frozen lake. \n",
            "For three days they hunted, but they had nothing to \n",
            "show for it. The third night a windstorm came up. They \n",
            "lay in their tent listening to the wind howling and the \n",
            "trees whipping back and forth. \n",
            "\n",
            "\n",
            "To see the storm better, the hunter opened the tent \n",
            "flap. What he saw startled him. There wasn't a breath \n",
            "of air, stirring, and the trees were standing perfectly still. \n",
            "Yet he could hear the wind howling. And the more he \n",
            "listened, the more it sounded as if it were calling DeFago's \n",
            "name. \n",
            "\n",
            "\n",
            "\"Da-faaaaaaaaay-go!\" it called. ''Da-faaaaaaaaay-go!'' \n",
            "\n",
            "\n",
            "\"I must be losing my mind,\" the hunter thought. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "But DeFago had gotten out of his sleeping bag. He \n",
            "was huddled in a corner of the tent, his head buried in \n",
            "his arms. \n",
            "\n",
            "\n",
            "\"What's this all about?\" the hunter asked. \n",
            "\n",
            "\n",
            "\"It's nothing,\" DeFago said. \n",
            "\n",
            "\n",
            "But the wind continued to call to him. And DeFago \n",
            "became more tense and more restless. \n",
            "\n",
            "\n",
            "\"Da-Faaaaaaaaay-go!\" it called. \"Da-faaaaaaaaay-go!\" \n",
            "\n",
            "\n",
            "Suddenly, he jumped to his feet, and he began to run \n",
            "from the tent. But the hunter grabbed him and wrestled \n",
            "him to the ground. \n",
            "\n",
            "\n",
            "\"You can't leave me out here,\" the hunter shouted. \n",
            "\n",
            "\n",
            "Then the wind called again, and DeFago broke loose \n",
            "and ran into the darkness. The hunter could hear him \n",
            "screaming as he went. Again and again he cried, \"Oh, \n",
            "my fiery feet, my burning feet of fire . . .\" Then his \n",
            "voice faded away, and the wind died down. \n",
            "\n",
            "\n",
            "At daybreak, the hunter followed DeFago's tracks in \n",
            "the snow. They went through the woods, down toward \n",
            "the lake, then out onto the ice. \n",
            "\n",
            "\n",
            "But soon he noticed something strange. The steps \n",
            "DeFago had taken got longer and longer. They were so \n",
            "long no human being could have taken them. It was as \n",
            "if something had helped him to hurry away. \n",
            "\n",
            "\n",
            "The hunter followed the tracks out to the middle of \n",
            "the lake, but there they disappeared. At first, he thought \n",
            "that DeFago had fallen through the ice, but there wasn't \n",
            "any hole. Then he thought that something had pulled \n",
            "him off the ice into the sky. But that made no sense. \n",
            "\n",
            "\n",
            "As he stood wondering what had happened, the wind \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "I \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "picked up again. Soon it was howling as it had the night \n",
            "before. Then he heard DeFago's voice. It was coming \n",
            "from up above, and again he heard DeFago screaming, \n",
            "• . My fiery feet, my burning feet . . .\" But there \n",
            "was nothing to be seen. \n",
            "\n",
            "\n",
            "Now the hunter wanted to leave that place as fast as \n",
            "he could.\n",
            "\n",
            "[410 | 603.47] loss=0.03 avg=0.22\n",
            "[420 | 617.63] loss=0.03 avg=0.22\n",
            "[430 | 631.79] loss=0.02 avg=0.21\n",
            "[440 | 645.96] loss=0.02 avg=0.20\n",
            "[450 | 660.12] loss=0.03 avg=0.20\n",
            "[460 | 674.28] loss=0.02 avg=0.19\n",
            "[470 | 688.44] loss=0.02 avg=0.19\n",
            "[480 | 702.63] loss=0.03 avg=0.19\n",
            "[490 | 716.81] loss=0.02 avg=0.18\n",
            "[500 | 730.97] loss=0.02 avg=0.18\n",
            "[510 | 745.13] loss=0.02 avg=0.17\n",
            "[520 | 759.29] loss=0.03 avg=0.17\n",
            "[530 | 773.45] loss=0.02 avg=0.17\n",
            "[540 | 787.61] loss=0.03 avg=0.16\n",
            "[550 | 801.77] loss=0.02 avg=0.16\n",
            "[560 | 815.93] loss=0.03 avg=0.16\n",
            "[570 | 830.08] loss=0.02 avg=0.15\n",
            "[580 | 844.24] loss=0.03 avg=0.15\n",
            "[590 | 858.39] loss=0.02 avg=0.15\n",
            "[600 | 872.55] loss=0.02 avg=0.15\n",
            "======== SAMPLE 1 ========\n",
            " of that, too. It was deep in the \n",
            "woods where Sam was staying, and it was coming up \n",
            "again. \n",
            "\n",
            "\n",
            "Sam's dog followed the tracks out to the middle of \n",
            "the lake, but he couldn't see it. \n",
            "\n",
            "\n",
            "\"Maybe it's them,\" he said. \n",
            "\n",
            "\n",
            "\"Maybe it's them,\" she said. \n",
            "\n",
            "\n",
            "She drove home over a dead-end street, into \n",
            "the countryside. She saw a woman walking ahead of her, \n",
            "with a basket in her hand. The woman looked her \n",
            "back step more closely than Sam did. \n",
            "\n",
            "\n",
            "But she was covered with sweat and trembling \n",
            "with fear. \n",
            "\n",
            "\n",
            "For a moment she thought she'd be able to see the woman again. \n",
            "But she was filled with terror. \n",
            "\n",
            "\n",
            "Then she began to take \n",
            "the steps again. But she was stopped because she was \n",
            "terrifying. \n",
            "\n",
            "\n",
            "\"Why are you doing this?\" she asked. \n",
            "\n",
            "\n",
            "\"Because you were scared,\" the man said. \n",
            "\n",
            "\n",
            "To see the man, we recommend the best-loved movies of all time, \n",
            "The Godfather, The Winter's \n",
            "Tale, and The Winter's \n",
            "terrace. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "But he didn't come back. And yet the woman \n",
            "was standing there with him. She told him who \n",
            "had killed her and buried him, and that she \n",
            "had \n",
            "seen to it that she be buried with him. \n",
            "\n",
            "\n",
            "And he said, \"May I stand in his way?\" \n",
            "\n",
            "\n",
            "She began to walk again and behind her, but \n",
            "he grabbed her and wrestled \n",
            "to keep her off the grave. \n",
            "\n",
            "\n",
            "She went to calling church-house bells every hour or so \n",
            "but the telephone rang. Her phone rang. \n",
            "\n",
            "\n",
            "• THE BABYSITTER • \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "“Maybe it's your mother,\" said Doreen. She picked \n",
            "up the phone. Before she could say a word, a man laughed \n",
            "hysterically and hung up. \n",
            "\n",
            "\n",
            "“Who was it?\" asked Richard. \n",
            "\n",
            "\n",
            "“Some nut,\" said Doreen. “What did I miss?\" \n",
            "\n",
            "\n",
            "At nine-thirty the telephone rang again. Doreen an- \n",
            "swered it. It was the man who had called before. “I'll \n",
            "be there soon,\" he said, and he laughed and hung up. \n",
            "\n",
            "\n",
            "“Who was it?\" the children asked. \n",
            "\n",
            "\n",
            "“Some crazy person,\" she said. \n",
            "\n",
            "\n",
            "About ten o'clock the telephone rang again. Jenny got \n",
            "to it first. \n",
            "\n",
            "\n",
            "“Hello,\" she said. \n",
            "\n",
            "\n",
            "It was the same man. “One more hour,\" he said, and \n",
            "he laughed and hung up. \n",
            "\n",
            "\n",
            "“He said, 'One more hour.' What did he mean?\" asked \n",
            "Jenny. \n",
            "\n",
            "\n",
            "“Don't worry,\" said Doreen. “It's somebody fooling \n",
            "around.\" \n",
            "\n",
            "\n",
            "“I'm scared,\" said Jenny. \n",
            "\n",
            "\n",
            "About ten-thirty the telephone rang once more. When \n",
            "Doreen picked it up, the man said, “Pretty soon now,\" \n",
            "and he laughed. \n",
            "\n",
            "\n",
            "\" Why are you doing this?\" Doreen screamed, and he \n",
            "hung up. \n",
            "\n",
            "\n",
            "“Was it that guy again?\" asked Brian. \n",
            "\n",
            "\n",
            "“Yes,\" said Doreen. \"I'm going to call the operator \n",
            "and complain.\" \n",
            "\n",
            "\n",
            "The operator told her to call back if it happened again. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "and she would try to trace the call. \n",
            "\n",
            "\n",
            "At eleven o'clock the telephone rang again. Doreen \n",
            "answered it. \"Very soon now/' the man said, and he \n",
            "laughed and hung up. \n",
            "\n",
            "\n",
            "Doreen called the operator. Almost at once she called \n",
            "back. \"That person is calling from a telephone upstairs,\" \n",
            "she said. \"You'd better leave. I'll get the police.\" \n",
            "\n",
            "\n",
            "Just then a door upstairs opened. A man they had \n",
            "never seen before started down the stairs toward them. \n",
            "As they ran from the house, he was smiling in a very \n",
            "strange way. A few minutes later, the police found him \n",
            "there and arrested him. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "A widow lived alone on the top floor of an apartment \n",
            "house. One morning her telephone rang. \n",
            "\n",
            "\n",
            "“Hello/' she said. \n",
            "\n",
            "\n",
            "“This is the viper,\" a man said. “I'm coming up.\" \n",
            "\n",
            "\n",
            "\n",
            "[610 | 895.34] loss=0.02 avg=0.14\n",
            "[620 | 909.49] loss=0.02 avg=0.14\n",
            "[630 | 923.65] loss=0.02 avg=0.14\n",
            "[640 | 937.81] loss=0.02 avg=0.13\n",
            "[650 | 951.97] loss=0.02 avg=0.13\n",
            "[660 | 966.13] loss=0.02 avg=0.13\n",
            "[670 | 980.29] loss=0.02 avg=0.13\n",
            "[680 | 994.44] loss=0.02 avg=0.13\n",
            "[690 | 1008.61] loss=0.02 avg=0.12\n",
            "[700 | 1022.77] loss=0.02 avg=0.12\n",
            "[710 | 1036.93] loss=0.02 avg=0.12\n",
            "[720 | 1051.09] loss=0.02 avg=0.12\n",
            "[730 | 1065.25] loss=0.02 avg=0.12\n",
            "[740 | 1079.40] loss=0.02 avg=0.11\n",
            "[750 | 1093.57] loss=0.02 avg=0.11\n",
            "[760 | 1107.72] loss=0.02 avg=0.11\n",
            "[770 | 1121.89] loss=0.02 avg=0.11\n",
            "[780 | 1136.04] loss=0.02 avg=0.11\n",
            "[790 | 1150.20] loss=0.02 avg=0.10\n",
            "[800 | 1164.36] loss=0.02 avg=0.10\n",
            "======== SAMPLE 1 ========\n",
            " so that she may \n",
            "fit in.\" \n",
            "\n",
            "\n",
            "This time the person's father made coffee. \n",
            "\n",
            "\n",
            "Fillies, he asked, \"When will we be able to rent a car?\" \n",
            "\n",
            "\n",
            "She got a ride in this car, too. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "• THE SLITHERY-DEE ■ \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The slithery-dee. \n",
            "\n",
            "\n",
            "He came up to it one day. \n",
            "\n",
            "\n",
            "He looked at my father. \"It's him,\" he \n",
            "said. \"I'll do it.\" \n",
            "\n",
            "\n",
            "I thought about him for a while. Then he \n",
            "turned off his recorder. Then he \n",
            "turned on his mixer. Then he turned on his fire \n",
            "and started putting things together. \n",
            "\n",
            "\n",
            "It was a fairly simple dance: \n",
            "\n",
            "\n",
            "First, he drop your feet. Then start \n",
            "getting your feet wet. \n",
            "\n",
            "\n",
            "Then start moving. \n",
            "\n",
            "\n",
            "This isn't a very formal dance, does it? \n",
            "There isn't a lot of repetition. So \n",
            "do it here. \n",
            "\n",
            "\n",
            "In a version called the slithery-dee, the slithery-dee \n",
            "wanted to feel good about himself. He changed the \n",
            "speed by moving his feet. So you could it? \n",
            "\n",
            "\n",
            "“Yes,\" he said. \"I'll do it.\" \n",
            "\n",
            "\n",
            "The night was quiet. The slithery-dee didzed off again. \n",
            "He went to sleep. In the morning he called \n",
            "Brian. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "“Hello,\" Brian said. \n",
            "\n",
            "\n",
            "He boarded a dark-sided carrying cart \n",
            "and went to the dance. He unpacked, then sat \n",
            "down in front of the counter. \n",
            "\n",
            "\n",
            "\"What's this all about?\" he asked. \n",
            "\n",
            "\n",
            "No answer. \n",
            "\n",
            "\n",
            "He began to wonder if something was wrong, if the \n",
            "demonstrated any danger. But no sound came up. \n",
            "\n",
            "\n",
            "Finally he found a song and a lightened lamp. He \n",
            "opened the song, and found in it the voice of a \n",
            "brave woman. \n",
            "\n",
            "\n",
            "\"I'll be there by midnight,\" she said. \"I'll be there \"fast.\" \n",
            "\n",
            "\n",
            "The boy could not believe his ears. His friend had \n",
            "seen to that. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "A businessman arrived at a hotel late one night to visit his \n",
            "young daughter. The room was very small, but they would- \n",
            "wanted to split the room. He and his friend argued a little, \n",
            "but they decided that the girl should sleep in the front hall. \n",
            "\n",
            "\n",
            "The door shut back easy-like, and there wasn't a sound. \n",
            "The businessman was trembling a little, but he finally opened \n",
            "the door. This time the voice said, \"Cover me.\" \n",
            "\n",
            "\n",
            "It was the stranger. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "“What do I come for?\" he said. “I come — for YOU!” \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "• ME TIE DOUGH-TY WALKER! \n",
            "\n",
            "There was a haunted house where every night a bloody \n",
            "head fell down the chimney. At least that's what people \n",
            "said. So nobody would stay there overnight. \n",
            "\n",
            "\n",
            "Then a rich man offered two hundred dollars to who- \n",
            "ever would do it. And this boy said he would try if he \n",
            "could have his dog with him. So it was all settled. \n",
            "\n",
            "\n",
            "The very next night the boy went to the house with \n",
            "his dog. To make it more cheerful, he started a fire in \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the fireplace. Then he sat in front of the fire and waited, \n",
            "and his dog waited with him. \n",
            "\n",
            "\n",
            "For a while nothing happened. But a little after mid- \n",
            "night he heard someone singing softly and sadly off in \n",
            "the woods. The singing sounded something like this: \n",
            "\n",
            "\n",
            "\"Me tie dough-ty walker!\" \n",
            "\n",
            "\n",
            "\"It's just somebody singing,\" the boy told himself, but \n",
            "he was frightened. \n",
            "\n",
            "\n",
            "Then his dog answered the song! Softly and sadly, it \n",
            "sang: \n",
            "\n",
            "\n",
            "\"Lynchee kinchy colly molly dingo dingo!\" \n",
            "\n",
            "\n",
            "The boy could not believe his ears. His dog had never \n",
            "uttered a word before. Then a few minutes later, he heard \n",
            "the singing again. Now it was closer and louder, but \n",
            "the words were the same: \n",
            "\n",
            "\n",
            "\"Me tie dough-ty walker!\" \n",
            "\n",
            "\n",
            "This time the boy tried to stop his dog from answering. \n",
            "He was afraid that whoever was singing would hear it \n",
            "and come after them. \n",
            "\n",
            "\n",
            "But his dog paid no attention, and\n",
            "\n",
            "[810 | 1187.19] loss=0.01 avg=0.10\n",
            "[820 | 1201.35] loss=0.02 avg=0.10\n",
            "[830 | 1215.53] loss=0.02 avg=0.10\n",
            "[840 | 1229.70] loss=0.02 avg=0.10\n",
            "[850 | 1243.87] loss=0.02 avg=0.10\n",
            "[860 | 1258.03] loss=0.02 avg=0.09\n",
            "[870 | 1272.19] loss=0.02 avg=0.09\n",
            "[880 | 1286.35] loss=0.02 avg=0.09\n",
            "[890 | 1300.53] loss=0.02 avg=0.09\n",
            "[900 | 1314.70] loss=0.02 avg=0.09\n",
            "[910 | 1328.87] loss=0.02 avg=0.09\n",
            "[920 | 1343.02] loss=0.02 avg=0.09\n",
            "[930 | 1357.18] loss=0.02 avg=0.09\n",
            "[940 | 1371.34] loss=0.02 avg=0.08\n",
            "[950 | 1385.49] loss=0.02 avg=0.08\n",
            "[960 | 1399.64] loss=0.02 avg=0.08\n",
            "[970 | 1413.80] loss=0.02 avg=0.08\n",
            "[980 | 1427.95] loss=0.02 avg=0.08\n",
            "[990 | 1442.11] loss=0.02 avg=0.08\n",
            "[1000 | 1456.32] loss=0.02 avg=0.08\n",
            "Saving checkpoint/run1/model-1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_simple.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "metadata": {
        "id": "dLOTnlZTT0YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gpt2_simple.load_gpt2(sess, run_name='run1')\n",
        "def generate_scary(path):\n",
        "  #caption=generate_caption_rand(path)\n",
        "  #caption_a=remove_start_end(caption)\n",
        "  gpt2_simple.generate(sess, run_name='run1',prefix=path,length=250)"
      ],
      "metadata": {
        "id": "-Wfei7B-Zquk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_scary(\"woman in black shirt and pink shorts is sitting on bench outside my door\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WVqXj1zZtir",
        "outputId": "7268bd3a-ea54-4673-fb9e-d91245a5d9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woman in black shirt and pink shorts is sitting on bench outside my door. \n",
            "\"Would you like to come in and have some cocoa?\" \n",
            "she asked. \n",
            "\n",
            "\n",
            "\"No,\" said I, \"I've got to go home.\" \n",
            "\n",
            "\n",
            "She went around to the other side of the car to let \n",
            "her friend out. From the window, she saw a small house in the \n",
            "upfield. \n",
            "\n",
            "\n",
            "\"Would you like to come in and have some cocoa?\" \n",
            "she asked. \n",
            "\n",
            "\n",
            "\"No,\" said I, \"I've got to go home.\" \n",
            "\n",
            "\n",
            "She went around to the other side of the car to let \n",
            "her friend out. From the window, she saw a small house in the \n",
            "upfield. \n",
            "\n",
            "\n",
            "\"Would you like to come in and have some cocoa?\" \n",
            "she asked. \n",
            "\n",
            "\n",
            "\"No,\" said I, \"I've got to go home.\" \n",
            "\n",
            "\n",
            "She went around to the other side of the car to let \n",
            "her friend out. From the window, she saw a small house in the \n",
            "upfield. \n",
            "\n",
            "\n",
            "\"Would you like to come in and have some cocoa?\" \n",
            "she asked. \n",
            "\n",
            "\n",
            "\"No,\" said I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_simple.finetune(sess, dataset=\"/content/drive/MyDrive/NLP project/Text Corpus/humour.txt\", \n",
        "                     steps=1000, \n",
        "                     model_name='124M',\n",
        "                     sample_every=200, \n",
        "                     save_every=1000, \n",
        "                     print_every=10, \n",
        "                     restore_from='fresh', \n",
        "                     run_name='funny_train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkcA3oZMaAMM",
        "outputId": "47196b53-2406-486e-b04d-dbc79bfd01d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Restoring parameters from models/124M/model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 2503 tokens\n",
            "Training...\n",
            "[10 | 17.92] loss=1.19 avg=1.19\n",
            "[20 | 32.10] loss=0.38 avg=0.78\n",
            "[30 | 46.26] loss=0.09 avg=0.55\n",
            "[40 | 60.43] loss=0.02 avg=0.41\n",
            "[50 | 74.61] loss=0.03 avg=0.34\n",
            "[60 | 88.78] loss=0.01 avg=0.28\n",
            "[70 | 102.96] loss=0.02 avg=0.24\n",
            "[80 | 117.13] loss=0.02 avg=0.21\n",
            "[90 | 131.30] loss=0.01 avg=0.19\n",
            "[100 | 145.46] loss=0.01 avg=0.17\n",
            "[110 | 159.62] loss=0.01 avg=0.16\n",
            "[120 | 173.77] loss=0.01 avg=0.14\n",
            "[130 | 187.93] loss=0.01 avg=0.13\n",
            "[140 | 202.08] loss=0.01 avg=0.12\n",
            "[150 | 216.23] loss=0.01 avg=0.12\n",
            "[160 | 230.39] loss=0.01 avg=0.11\n",
            "[170 | 244.54] loss=0.01 avg=0.10\n",
            "[180 | 258.70] loss=0.01 avg=0.10\n",
            "[190 | 272.85] loss=0.01 avg=0.09\n",
            "[200 | 287.00] loss=0.01 avg=0.09\n",
            "======== SAMPLE 1 ========\n",
            " About the Watch: It is the Watchers No. 90.\n",
            "\n",
            "\n",
            "\n",
            "A farmer was sitting in the neighborhood bar getting drunk. A man came in and asked the farmer, \"Hey, why are you sitting here on this beautiful day, getting drunk?\" The farmer shook his head and replied, \"Some things you just can't explain.\"\n",
            "\"So what happened that's so horrible?\" the man asked as he got his drink\n",
            "\"Well,\" the farmer said, \"today I was sitting by my cow, milking her. Just as I got the bucket full, she lifted her left leg and kicked over the bucket.\"\n",
            "\"Okay,\" said the man, \"but that's not so bad.\" \"Some things you just can't explain,\" the farmer replied. \"So what happened then?\" the man asked. The farmer said, \"I took her left leg and tied it to the post on the left.\"\n",
            "\"And then?\"\n",
            "\"Well, I sat back down and continued to milk her. Just as I got the bucket full, she took her right leg and kicked over the bucket.\"\n",
            "The man laughed and said, \"Again?\" The farmer replied, \"Some things you just can't explain.\" \"So, what did you do then?\" the man asked.\n",
            "\"I took her right leg this time and tied it to the post on the right.\"\n",
            "\"And then?\"\n",
            "\"Well, I sat back down and began milking her again. Just as I got the bucket full, the stupid cow knocked over the bucket with her tail.\"\n",
            "\"Hmmm,\" the man said and nodded his head. \"Some things you just can't explain,\" the farmer said.\n",
            "\"So, what did you do?\" the man asked.\n",
            "\"Well,\" the farmer said, \"I didn't have anymore rope, so I took off my belt and tied her tail to the rafter. In that moment, my pants fell down and my wife walked in ... Some things you just can't explain.\"\n",
            "\n",
            "\n",
            "\n",
            "An Irishman walks into a bar in Dublin, orders three pints of Guinness and sits in the back of the room, drinking a sip out of each one in turn. When he finished all three, he comes back to the bar and orders three more. The bartender says to him, 'You know, a pint goes flat after I draw it; it would taste better if you bought one at a time.' The Irishman replies, 'Well, you see, I have two brothers. One is in America, the other in Australia, and I'm here in Dublin. When we all left home, we promised that we'd drink this way to remember the days we all drank together. 'The bartender admits that this is a nice custom, and leaves it there. The Irishman becomes a regular in the bar and always drinks the same way: he orders three pints and drinks the three pints by taking drinks from each of them in turn. One day, he comes in and orders two pints. All the other regulars in the bar notice and fall silent. When he comes back to the bar for the second round, the bartender says, 'I don't want to intrude on your grief, but I wanted to offer my condolences on your great loss.' The Irishman looks confused for a moment, then a lights dawns in his eye and he laughs. 'Oh, no, ' he says, 'Everyone is fine. I've just quit drinking!\n",
            "\n",
            "\n",
            "\n",
            "A man stopped at his favorite watering hole after a hard days work to relax. He noticed a man next to him ordered a shot and a beer. The man drank the shot, chased it with the beer and then looked into his shirt pocket. This continued several times before the man's curiosity got the best of him. He leaned over to the guy and said, \"Excuse me, I couldn't help but notice your little ritual, why in the world do you look into your shirt pocket every time you drink your shot & beer\"? The man replied, \"There's a picture of my wife in there, and when she starts lookin' good, I'm headin' home\"!\n",
            "\n",
            "\n",
            "\n",
            "A man in his 40's bought a new BMW and was out on the interstate for a nice evening drive. The top was down, the breeze was blowing through what was left of his hair and he decided to open her up. As the needle jumped up to 80 mph, he suddenly saw flashing red and blue lights behind him. \"There's no way they can catch a BMW,\" he thought to himself and opened her up further. The needle hit 90, 100.... Then the reality of the situation hit him. \"What the hell am I doing?\" he thought and pulled over. The cop came up to him, took his license without a word and examined it and the car.\n",
            "\"It's been a long day, this is the end of my shift and it's Friday the 13th. I don't feel like more paperwork,\n",
            "\n",
            "[210 | 310.77] loss=0.01 avg=0.08\n",
            "[220 | 324.92] loss=0.01 avg=0.08\n",
            "[230 | 339.07] loss=0.01 avg=0.08\n",
            "[240 | 353.22] loss=0.01 avg=0.07\n",
            "[250 | 367.39] loss=0.01 avg=0.07\n",
            "[260 | 381.57] loss=0.01 avg=0.07\n",
            "[270 | 395.72] loss=0.01 avg=0.06\n",
            "[280 | 409.87] loss=0.01 avg=0.06\n",
            "[290 | 424.01] loss=0.01 avg=0.06\n",
            "[300 | 438.17] loss=0.01 avg=0.06\n",
            "[310 | 452.31] loss=0.01 avg=0.06\n",
            "[320 | 466.47] loss=0.01 avg=0.05\n",
            "[330 | 480.62] loss=0.01 avg=0.05\n",
            "[340 | 494.77] loss=0.01 avg=0.05\n",
            "[350 | 508.92] loss=0.01 avg=0.05\n",
            "[360 | 523.07] loss=0.01 avg=0.05\n",
            "[370 | 537.21] loss=0.01 avg=0.05\n",
            "[380 | 551.37] loss=0.01 avg=0.05\n",
            "[390 | 565.52] loss=0.01 avg=0.04\n",
            "[400 | 579.66] loss=0.01 avg=0.04\n",
            "======== SAMPLE 1 ========\n",
            " sinking. The doctor took one look and told her to take him to the ER. She feared something along the lines of an intestinal rupture. About half way to the hospital, my friend suddenly let rip the loudest, most powerful fart any of us had ever heard. I swear to God he levitated. We thought the upholstery in the car seat had ripped. After a good 30 seconds of intense farting, he looked at his mom and said, I feel all better now!\n",
            "\n",
            "\n",
            "\n",
            "One of my wifes third graders was wearing a Fitbit watch, which prompted my wife to ask, Are you tracking your steps? No, said the little girl. I wear this for Mommy so she can show Daddy when he gets home.\n",
            "\n",
            "\n",
            "\n",
            "A farmer was sitting in the neighborhood bar getting drunk. A man came in and asked the farmer, \"Hey, why are you sitting here on this beautiful day, getting drunk?\" The farmer shook his head and replied, \"Some things you just can't explain.\"\n",
            "\"So what happened that's so horrible?\" the man asked as he sat down next to the farmer.\n",
            "\"Well,\" the farmer said, \"today I was sitting by my cow, milking her. Just as I got the bucket full, she lifted her left leg and kicked over the bucket.\"\n",
            "\"Okay,\" said the man, \"but that's not so bad.\" \"Some things you just can't explain,\" the farmer replied. \"So what happened then?\" the man asked. The farmer said, \"I took her left leg and tied it to the post on the left.\"\n",
            "\"And then?\"\n",
            "\"Well, I sat back down and continued to milk her. Just as I got the bucket full, she took her right leg and kicked over the bucket.\"\n",
            "The man laughed and said, \"Again?\" The farmer replied, \"Some things you just can't explain.\" \"So, what did you do then?\" the man asked.\n",
            "\"I took her right leg this time and tied it to the post on the right.\"\n",
            "\"And then?\"\n",
            "\"Well, I sat back down and began milking her again. Just as I got the bucket full, the stupid cow knocked over the bucket with her tail.\"\n",
            "\"Hmmm,\" the man said and nodded his head. \"Some things you just can't explain,\" the farmer said.\n",
            "\"So, what did you do?\" the man asked.\n",
            "\"Well,\" the farmer said, \"I didn't have anymore rope, so I took off my belt and tied her tail to the rafter. In that moment, my pants fell down and my wife walked in ... Some things you just can't explain.\"\n",
            "\n",
            "\n",
            "\n",
            "An Irishman walks into a bar in Dublin, orders three pints of Guinness and sits in the back of the room, drinking a sip out of each one in turn. When he finished all three, he comes back to the bar and orders three more. The bartender says to him, 'You know, a pint goes flat after I draw it; it would taste better if you bought one at a time.' The Irishman replies, 'Well, you see, I have two brothers. One is in America, the other in Australia, and I'm here in Dublin. When we all left home, we promised that we'd drink this way to remember the days we all drank together. 'The bartender admits that this is a nice custom, and leaves it there. The Irishman becomes a regular in the bar and always drinks the same way: he orders three pints and drinks the three pints by taking drinks from each of them in turn. One day, he comes in and orders two pints. All the other regulars in the bar notice and fall silent. When he comes back to the bar for the second round, the bartender says, 'I don't want to intrude on your grief, but I wanted to offer my condolences on your great loss.' The Irishman looks confused for a moment, then a lights dawns in his eye and he laughs. 'Oh, no, ' he says, 'Everyone is fine. I've just quit drinking!\n",
            "\n",
            "\n",
            "\n",
            "A man stopped at his favorite watering hole after a hard days work to relax. He noticed a man next to him ordered a shot and a beer. The man drank the shot, chased it with the beer and then looked into his shirt pocket. This continued several times before the man's curiosity got the best of him. He leaned over to the guy and said, \"Excuse me, I couldn't help but notice your little ritual, why in the world do you look into your shirt pocket every time you drink your shot & beer\"? The man replied, \"There's a picture of my wife in there, and when she starts lookin' good, I'm headin' home\"!\n",
            "\n",
            "\n",
            "\n",
            "A man in his 40's bought a new BMW and was out on the interstate for a nice evening drive. The top\n",
            "\n",
            "[410 | 602.46] loss=0.01 avg=0.04\n",
            "[420 | 616.61] loss=0.01 avg=0.04\n",
            "[430 | 630.77] loss=0.01 avg=0.04\n",
            "[440 | 644.92] loss=0.01 avg=0.04\n",
            "[450 | 659.07] loss=0.01 avg=0.04\n",
            "[460 | 673.22] loss=0.01 avg=0.04\n",
            "[470 | 687.38] loss=0.01 avg=0.04\n",
            "[480 | 701.54] loss=0.01 avg=0.04\n",
            "[490 | 715.69] loss=0.01 avg=0.04\n",
            "[500 | 729.84] loss=0.01 avg=0.03\n",
            "[510 | 743.99] loss=0.01 avg=0.03\n",
            "[520 | 758.14] loss=0.01 avg=0.03\n",
            "[530 | 772.29] loss=0.01 avg=0.03\n",
            "[540 | 786.44] loss=0.00 avg=0.03\n",
            "[550 | 800.59] loss=0.01 avg=0.03\n",
            "[560 | 814.74] loss=0.01 avg=0.03\n",
            "[570 | 828.89] loss=0.01 avg=0.03\n",
            "[580 | 843.04] loss=0.01 avg=0.03\n",
            "[590 | 857.19] loss=0.01 avg=0.03\n",
            "[600 | 871.34] loss=0.01 avg=0.03\n",
            "======== SAMPLE 1 ========\n",
            " hell it took me a good six seconds to beat the crap out of you all. You little b******s!\n",
            "\n",
            "\n",
            "\n",
            "A Professor was traveling by boat. On his way he asked the sailor:\n",
            "Do you know Biology, Ecology, Zoology, Geography, physiology?\n",
            "The sailor said no to all his questions.\n",
            "Professor: What the hell do you know on earth. You will die of illiteracy.\n",
            "After a while the boat started sinking. The Sailor asked the Professor, do you know swiminology & escapology from sharkology?\n",
            "The professor said no.\n",
            "Sailor: Well, sharkology & crocodilogy will eat your assology, headology & you will dieology because of your mouthology.\n",
            "\n",
            "\n",
            "\n",
            "A police officer found a perfect hiding place for watching for speeding motorists.\n",
            "One day, the officer was amazed when everyone was under the speed limit, so he investigated and found the problem.\n",
            "A 10 years old boy was standing on the side of the road with a huge hand painted sign which said Radar Trap Ahead.\n",
            "A little more investigative work led the officer to the boys accomplice: another boy about 100 yards beyond the radar trap with a sign reading TIPS and a bucket at his feet full of change.\n",
            "\n",
            "\n",
            "\n",
            "After his return from Rome, Will couldnt find his luggage in the airport baggage area. He went to the lost luggage office and told the woman there that his bags hadnt shown up on the carousel.\n",
            "She smiled and told him not to worry because they were trained professionals and he was in good hands.\n",
            "Then she asked Will, Has your plane arrived yet?\n",
            "\n",
            "\n",
            "\n",
            "A couple going on vacation but his wife was on a business trip so he went to the destination first and his wife would meet him the next day.\n",
            "When he reached his hotel, he decided to send his wife a quick email.\n",
            "Unfortunately, when typing her address, he mistyped a letter and his note was directed instead to an elderly preachers wife whose husband had passed away only the day before.\n",
            "When the grieving widow checked her email, she took one look at the monitor, let out a piercing scream, and fell to the floor in a dead faint.\n",
            "At the sound, her family rushed into the room and saw this note on the screen:\n",
            "Dearest Wife,\n",
            "Just got checked in. Everything prepared for your arrival tomorrow.\n",
            "P.S. Sure is hot down here.\n",
            "\n",
            "\n",
            "\n",
            "A curious child asked his mother: Mommy, why are some of your hairs turning grey?\n",
            "The mother tried to use this occasion to teach her child: It is because of you, dear. Every bad action of yours will turn one of my hairs grey!\n",
            "The child replied innocently: Now I know why grandmother has only grey hairs on her head.\n",
            "\n",
            "\n",
            "\n",
            "During my sophomore year of high school, we were doing silent work and my history teacher said that we could listen to music but if it was too loud he would break our headphones. so Im doing my work quietly with my music on low, and this obnoxious kid sitting next to me had his music really loud. I could hear it over my music but ignored it. My teacher thought it was me. So he comes up to me & ripped my BRAND NEW Apple headphones, looking ruthless. He suddenly realized it was the guy next to me and he was completely embarrassed. He came in the next day with a new pair and an apology note taped to them. He couldnt look me in the eye for the rest of the year.\n",
            "\n",
            "\n",
            "\n",
            "I have a friend who Ive known since I was very little. One day, when he was six, I was at his house when he got this absolutely god-awful stomach pain. I mean, he was literally writhing in pain. So, his mom took him to the doctors office, where the doctor took one look and told her to take him to the ER. She feared something along the lines of an intestinal rupture. About half way to the hospital, my friend suddenly let rip the loudest, most powerful fart any of us had ever heard. I swear to God he levitated. We thought the upholstery in the car seat had ripped. After a good 30 seconds of intense farting, he looked at his mom and said, I feel all better now!\n",
            "\n",
            "\n",
            "\n",
            "One of my wifes third graders was wearing a Fitbit watch, which prompted my wife to ask, Are you tracking your steps? No, said the little girl. I wear this for Mommy so she can show Daddy when he gets home.\n",
            "\n",
            "\n",
            "\n",
            "A farmer was sitting in the neighborhood bar getting drunk. A man came in and asked the farmer, \"Hey, why are you sitting here on this beautiful day, getting drunk?\" The farmer shook his head and replied, \"Some things you just can't explain.\"\n",
            "\"So what happened that's so horrible?\" the man asked as he sat down next to the\n",
            "\n",
            "[610 | 894.13] loss=0.01 avg=0.03\n",
            "[620 | 908.28] loss=0.01 avg=0.03\n",
            "[630 | 922.43] loss=0.01 avg=0.03\n",
            "[640 | 936.58] loss=0.01 avg=0.03\n",
            "[650 | 950.73] loss=0.00 avg=0.03\n",
            "[660 | 964.88] loss=0.01 avg=0.03\n",
            "[670 | 979.03] loss=0.01 avg=0.03\n",
            "[680 | 993.18] loss=0.01 avg=0.02\n",
            "[690 | 1007.33] loss=0.00 avg=0.02\n",
            "[700 | 1021.48] loss=0.01 avg=0.02\n",
            "[710 | 1035.86] loss=0.01 avg=0.02\n",
            "[720 | 1050.01] loss=0.01 avg=0.02\n",
            "[730 | 1064.16] loss=0.01 avg=0.02\n",
            "[740 | 1078.30] loss=0.01 avg=0.02\n",
            "[750 | 1092.44] loss=0.01 avg=0.02\n",
            "[760 | 1106.59] loss=0.01 avg=0.02\n",
            "[770 | 1120.74] loss=0.00 avg=0.02\n",
            "[780 | 1134.88] loss=0.01 avg=0.02\n",
            "[790 | 1149.03] loss=0.01 avg=0.02\n",
            "[800 | 1163.17] loss=0.00 avg=0.02\n",
            "======== SAMPLE 1 ========\n",
            ". Now there is no such thing as an animal beginning with M.\n",
            "For example, sharkology begins with sharkology.\n",
            "Sailor: Well, sharkology begins with tailology, so start tailology!\n",
            "After a while the boat started sinking. The Sailor asked the Professor, do you know swiminology & crocodilogy crocodilogy can you guess what's up?\n",
            "The professor said no.\n",
            "Sailor: Well, sharkology begins with sharkology, so start tailology!\n",
            "Sailor: Well, sharkology begins with sharkology, so start tailology!\n",
            "Sailor: Well, sharkology begins with sharkology, so start tailology!\n",
            "Sailor: Well, sharkology begins with sharkology, so start tailology!\n",
            "Sailor: Well, sharkology begins with sharkology, so start tailology!\n",
            "Sailor: Well, sharkology begins with sharkology, so start tailology!\n",
            "\n",
            "\n",
            "\n",
            "During my sophomore year of high school, we were doing silent work and my history teacher said that we could listen to music but if it was too loud he would break our headphones. so Im doing my work quietly with my music on low, and this obnoxious kid sitting next to me had his music really loud. I could hear it over my music but ignored it. My teacher thought it was me. So he comes up to me & ripped my BRAND NEW Apple headphones, looking ruthless. He suddenly realized it was the guy next to me and he was completely embarrassed. He came in the next day with a new pair and an apology note taped to them. He couldnt look me in the eye for the rest of the year.\n",
            "\n",
            "\n",
            "\n",
            "I have a friend who Ive known since I was very little. One day, when he was six, I was at his house when he got this absolutely god-awful stomach pain. I mean, he was literally writhing in pain. So, his mom took him to the doctors office, where the doctor took one look and told her to take him to the ER. She feared something along the lines of an intestinal rupture. About half way to the hospital, my friend suddenly let rip the loudest, most powerful fart any of us had ever heard. I swear to God he levitated. We thought the upholstery in the car seat had ripped. After a good 30 seconds of intense farting, he looked at his mom and said, I feel all better now!\n",
            "\n",
            "\n",
            "\n",
            "One of my wifes third graders was wearing a Fitbit watch, which prompted my wife to ask, Are you tracking your steps? No, said the little girl. I wear this for Mommy so she can show Daddy when he gets home.\n",
            "\n",
            "\n",
            "\n",
            "A farmer was sitting in the neighborhood bar getting drunk. A man came in and asked the farmer, \"Hey, why are you sitting here on this beautiful day, getting drunk?\" The farmer shook his head and replied, \"Some things you just can't explain.\"\n",
            "\"So what happened that's so horrible?\" the man asked as he sat down next to the farmer.\n",
            "\"Well,\" the farmer said, \"today I was sitting by my cow, milking her. Just as I got the bucket full, she lifted her left leg and kicked over the bucket.\"\n",
            "\"Okay,\" said the man, \"but that's not so bad.\" \"Some things you just can't explain,\" the farmer replied. \"So what happened then?\" the man asked. The farmer said, \"I took her left leg and tied it to the post on the left.\"\n",
            "\"And then?\"\n",
            "\"Well, I sat back down and continued to milk her. Just as I got the bucket full, she took her right leg and kicked over the bucket.\"\n",
            "The man laughed and said, \"Again?\" The farmer replied, \"Some things you just can't explain.\" \"So, what did you do then?\" the man asked.\n",
            "\"I took her right leg this time and tied it to the post on the right.\"\n",
            "\"And then?\"\n",
            "\"Well, I sat back down and began milking her again. Just as I got the bucket full, the stupid cow knocked over the bucket with her tail.\"\n",
            "\"Hmmm,\" the man said and nodded his head. \"Some things you just can't explain,\" the farmer said.\n",
            "\"So, what did you do?\" the man asked.\n",
            "\"Well,\" the farmer said, \"I didn't have anymore rope, so I took off my belt and tied her tail to the rafter. In that moment, my pants fell down and my wife walked in ... Some things you just can't explain.\"\n",
            "\n",
            "\n",
            "\n",
            "An Irishman walks into a bar in Dublin, orders three pints of Guinness and sits in the back of the room, drinking a sip out of each one in turn. When he finished all three, he comes back to the bar and orders three more. The bartender says to\n",
            "\n",
            "[810 | 1185.98] loss=0.01 avg=0.02\n",
            "[820 | 1200.12] loss=0.00 avg=0.02\n",
            "[830 | 1214.27] loss=0.01 avg=0.02\n",
            "[840 | 1228.42] loss=0.01 avg=0.02\n",
            "[850 | 1242.57] loss=0.01 avg=0.02\n",
            "[860 | 1256.71] loss=0.01 avg=0.02\n",
            "[870 | 1270.86] loss=0.00 avg=0.02\n",
            "[880 | 1285.01] loss=0.01 avg=0.02\n",
            "[890 | 1299.16] loss=0.01 avg=0.02\n",
            "[900 | 1313.32] loss=0.00 avg=0.02\n",
            "[910 | 1327.47] loss=0.01 avg=0.02\n",
            "[920 | 1341.61] loss=0.00 avg=0.02\n",
            "[930 | 1355.76] loss=0.00 avg=0.02\n",
            "[940 | 1369.91] loss=0.01 avg=0.02\n",
            "[950 | 1384.06] loss=0.00 avg=0.02\n",
            "[960 | 1398.20] loss=0.00 avg=0.02\n",
            "[970 | 1412.35] loss=0.01 avg=0.02\n",
            "[980 | 1426.50] loss=0.00 avg=0.02\n",
            "[990 | 1440.65] loss=0.00 avg=0.02\n",
            "[1000 | 1454.80] loss=0.01 avg=0.02\n",
            "Saving checkpoint/funny_train/model-1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_simple.copy_checkpoint_to_gdrive(run_name='funny_train')"
      ],
      "metadata": {
        "id": "DN3rIF04aBxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_humour(path):\n",
        "  gpt2_simple.generate(sess, run_name='funny_train',prefix=path,length=250)"
      ],
      "metadata": {
        "id": "8fu08NJafq4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_humour(\"woman in black shirt and pink shorts is sitting on bench outside my door\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mUvXa3xf0jS",
        "outputId": "17811269-5927-4aee-fc34-7fc2233c1f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woman in black shirt and pink shorts is sitting on bench outside my door.\n",
            "When he reached the post on the right, he suddenly realized it was the woman next to him.\n",
            "She smiled and told him not to worry because they were trained professionals and he was in good hands.\n",
            "Then she asked Will, Has your plane arrived yet?\n",
            "\n",
            "\n",
            "\n",
            "A couple going on vacation but his wife was on a business trip so he went to the destination first and his wife would meet him the next day.\n",
            "When he reached his hotel, he decided to send his wife a quick email.\n",
            "Unfortunately, when typing her address, he mistyped a letter and his note was directed instead to an elderly preachers wife whose husband had passed away only the day before.\n",
            "When the grieving widow checked her email, she took one look at the monitor, let out a piercing scream, and fell to the floor in a dead faint.\n",
            "At the sound, her family rushed into the room and saw this note on the screen:\n",
            "Dearest Wife,\n",
            "Just got checked in. Everything prepared for your arrival tomorrow.\n",
            "P.S. Sure is hot down here.\n",
            "\n",
            "\n",
            "\n",
            "A curious child asked his mother: Mommy, why are some of your hairs turning grey?\n",
            "The mother tried to use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_simple.finetune(sess, dataset=\"/content/drive/MyDrive/NLP project/Text Corpus/Scifi Dataset/Scifi1.txt\", steps=1000, model_name='124M',\n",
        "sample_every=200, save_every=1000, print_every=10, restore_from='fresh', run_name='scifi_f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXTFNuH0gkUi",
        "outputId": "ed130b0f-e35f-4a27-8030-0efbc9c71f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Restoring parameters from models/124M/model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 260381 tokens\n",
            "Training...\n",
            "[10 | 19.06] loss=3.64 avg=3.64\n",
            "[20 | 33.25] loss=3.98 avg=3.81\n",
            "[30 | 47.45] loss=3.85 avg=3.83\n",
            "[40 | 61.61] loss=3.49 avg=3.74\n",
            "[50 | 75.79] loss=3.71 avg=3.73\n",
            "[60 | 89.95] loss=3.39 avg=3.68\n",
            "[70 | 104.11] loss=4.03 avg=3.73\n",
            "[80 | 118.27] loss=3.17 avg=3.65\n",
            "[90 | 132.44] loss=3.36 avg=3.62\n",
            "[100 | 146.60] loss=3.40 avg=3.60\n",
            "[110 | 160.76] loss=3.21 avg=3.56\n",
            "[120 | 174.91] loss=3.33 avg=3.54\n",
            "[130 | 189.07] loss=3.08 avg=3.50\n",
            "[140 | 203.24] loss=3.57 avg=3.51\n",
            "[150 | 217.41] loss=3.33 avg=3.49\n",
            "[160 | 231.57] loss=3.00 avg=3.46\n",
            "[170 | 245.72] loss=3.18 avg=3.44\n",
            "[180 | 259.88] loss=2.77 avg=3.40\n",
            "[190 | 274.04] loss=2.25 avg=3.34\n",
            "[200 | 288.20] loss=2.74 avg=3.30\n",
            "======== SAMPLE 1 ========\n",
            " leveet of the city and the huge circular building rising in the middle... A man came out of the building, almost as though he were looking. He was covered with a silvery red cape and a black matted skin along his entire body. his eyes were wide with a sparkling red tint. A great long nose, two long ones at the sides of his foreheads and short   sharp teeth with black tipped clubs hanging out from them. He wore a gray, blunted shanghai shirt and black boots. As though he were possessed of some special sort of intelligence. \"Yah!\" said the Chief Engineer. \"You've all gone overto the Moon! See these scientists working on the Moon? You must have gotten over here with your tricks, eh?\" \"Yah!\" protested the man, \"We gotta go over.\" \"We've got to, eh?\" \"They got the biggest brains of themall!\" jeered Troy. The Chief Engineer rolled his eyes and turned to the girl. \"We're on our way all right.\" She shrugged and grinned. \"I could have sworn I saw them too. It wasn't your style.\" \"Maybe,\" said the Chief Engineer. He glanced around for a position of authority but was met by LeClarc. They all sat back and studied him curiously. His eyes were cold, expressionless and they didn't move. It was strange, because the Chief Engineer was a man of considerable eloquence -- but also a natural, able leader. Despite the fact that he lacked the emotional strength to speak. He spoke with the conviction of another man, but in his quiet manner. \"Now it's all the right ways to go over. You must be ready as soon as we get back.\" LeClarc turned his attention to the others, turning to LeClarc's companion, the man sitting at the foot of the bench. He spoke. \"If we have to... I want to go.\" \"We're on our way, eh?\" inquired LeClarc. \"I've known a Terran for a long time, but I never thought the Terran would take a woman, and I wonder how long this will last. Are we going to stay here for some reason?\" \"No,\" asserted LeClarc, \"I don't think we should. After all, what if the Terran had mutinies?\" \"Maybe we should try to,\" he grumbled irritably. \"But... we can't go anywhere without our help!\" \"Then why are we going?\" \"Well, we haven't got much more to give you than what you've got now. Then we may as well give up some of your ideas. There's no need for you to try anything new. We can start over. It'll be all right.\" \"Okay,\" agreed the Terran. \"Let's go talk to the Lieutenant again.\" They sat sitting there for a while, discussing the matter. LeClarc told them that all the science had established over the past year had been right and that everything over the previous two years had been completely correct. So far it seemed that nothing had changed and that LeClarc had certainly grown a great deal by the year he left Earth. Apparently he hadn't quite figured it out as a situation existed in which a man might have to work in various departments, and vice versa. But, no doubt, this made LeClarc's manner -- of which he generally spoke English -- rather unusual. So he seemed to be responding to the casual notion that although he had gained new experience from that experiment with neutron guns, he wasn't sure that he had mastered the art of thermonuclear warping. Still, the Lieutenant said that, for the most part, he accepted the premise of his study. As he walked from the ship to the Institute, his mind wandered to various aspects of life in the world. And of the neutron guns employed there. In general he had few thoughts of the necessity for such devices as they were today. That LeClarc had certainly been right. He considered the various weapons and their functions with a great deal of satisfaction. He could not doubt that this experiment had been a success. LeClarc, however -- LeClarc's companion -- was not completely satisfied. He could trace the reasons for LeClarc's return back to the earliest traces of their contact. Of the weapons, he considered it probable. They varied in design from man made to the most advanced in atom-bomb-electricity. Their effects were completely random. A single rocket would set them off in an arc, and disintegrate before the arc hit the ground. A neutron gun fired from a launch tube? Only one rocket would launch it off at a certain moment, and then set off with only a small circle of blinding radiation. And the whole thing was based on a false premise. There must have been no contact at all between LeClarc and his companion. They might have been telepaths. A man could impersonate a telepath with very little effort. And if they were\n",
            "\n",
            "[210 | 311.85] loss=2.61 avg=3.27\n",
            "[220 | 326.01] loss=2.70 avg=3.24\n",
            "[230 | 340.16] loss=2.40 avg=3.20\n",
            "[240 | 354.32] loss=2.47 avg=3.16\n",
            "[250 | 368.48] loss=2.78 avg=3.15\n",
            "[260 | 382.64] loss=2.82 avg=3.13\n",
            "[270 | 396.80] loss=2.05 avg=3.09\n",
            "[280 | 410.95] loss=2.14 avg=3.05\n",
            "[290 | 425.11] loss=2.02 avg=3.01\n",
            "[300 | 439.26] loss=2.45 avg=2.99\n",
            "[310 | 453.42] loss=1.70 avg=2.94\n",
            "[320 | 467.57] loss=2.10 avg=2.91\n",
            "[330 | 481.73] loss=2.20 avg=2.88\n",
            "[340 | 495.88] loss=1.94 avg=2.85\n",
            "[350 | 510.04] loss=1.63 avg=2.81\n",
            "[360 | 524.21] loss=1.76 avg=2.77\n",
            "[370 | 538.36] loss=1.75 avg=2.74\n",
            "[380 | 552.51] loss=2.44 avg=2.73\n",
            "[390 | 566.66] loss=2.06 avg=2.71\n",
            "[400 | 580.81] loss=2.44 avg=2.70\n",
            "======== SAMPLE 1 ========\n",
            " that a very short time ago. His mind didn't have a right to be swayed by anything, did it? What can you say to him now? It made him feel good.\" \"What's your name?\" \"Dorrek, Larwich. I'm Dulce.\" His father had died suddenly while holding him up before the eye. \"Your mother died of breast cancer when you were a little boy. What do you have to say about that?\" \"I have no business being banged about with men of science fiction who know what to do.\" \"Is that all you can say?\" \"No! Oh, that's all you can say. I won't listen to men who say they know everything. I'm only listening to the truth.\" \"Do you know what the girl's address is?\" \"She can only give me an idea. Maybe she lives in the hills.\" \"Will you make a specimen for us?\" \"Sure.\" \"What's the idea?\" \"Make it like her. Let her form her own mind when she gets to know you.\" The biologist eyed the young man questioningly. \"You two get along okay?\" Larwich whispered in his sleep. \"How do you feel?\" \"Good. Well -- I hate it when men try to change men. Tell me, Larwich: is it wrong to try to change me? I'm not a woman -- or an easy thing to be a woman like you are. Don't you see -- \" \"What do you mean?\" \"We're not trying to be changed. We are as change-making as you are. And that's in the eyes of God.\" Larwich lay down, touched the bed, then went upstairs. When he was out for a walk he went back to Larwich's place to see if he could find something to wear that wouldn't make him change his mind. When he found nothing, he went to Wells Fargo. When he began at right he went back to the bank and opened a branch each day. Some day he \"It's open till tomorrow\" came up. It didn't take long, and in less than an hour Wells Fargo was standing up. \"Who wants to come down?\" asked Larwich. \"We all love Wells Fargo. So do anyone else.\" \"Well, we get more out of life than ever. We can expect little by little more from our bank. The future we foresees is going to be better for it. So we're going to make it -- and we're going to make it fast.\" \"The way it looks to me,\" said Larwich, \"will be quite so long before we get all of usr's out of here, that we won't be able to use Wells Fargo for anything. Until then, we'll have better use of our money, and quick cash. When Will you be with us ri we got a little while ago. Let's get started.\" \"What time?\" Larwich asked. \"Twelve o'clock in the morning.\" He went on with the story. \"Well, that's when all the action was taking place around Wells Fargo -- \" A.D. twelve o'clock. Larwich got up, walked over to a booth. \"We'll have about a half an hour to get Wells Fargo to make a offer. You two here at once, be careful with the blonde, 'Til go, Larwich.\" The blonde was Lesterv, Larwich told himself. The blonde was the woman, and the question remained 'ask her.' At the moment he caught the unmistakable sign of disgust in her features. \"Oh yeah. I think she's in her element.\" He got up, walked over to the booth. Lesterv sat down. \"How's the new car doing?\" she asked. \"Better than the old car. I remember the smell. Like a lot of them's got 'em. Old 'Brockef. That's the word.\" \"Better than your average Dane,\" said Larwich. \"How big was the car?\" She grinned. \"Six or seven hp.\" He got up, walked over to the booth and sat down beside Lesterv. \"How's the new car doing?\" \"Better than the old car. How fast can you judge?\" He moved over, sat down beside the table and made a friendly gesture. She reached out with her hand.  The older man reached out too close, but Lesterv was too anxious to get out his hand. He closed his eyes and rested his hands on the armchairs set up for the elderly couple. They laughed for a minute, and he wondered if they worried him any more. Soon the silence of the room was deserted, and he could only peer inside out through the doorway. lTll see here, Larwich. I see the smile. It glints on people's lips and the things they say about you. When you're alone in this nightmare, you can't help it, and you never could've imagined that when you\n",
            "\n",
            "[410 | 603.51] loss=1.81 avg=2.68\n",
            "[420 | 617.66] loss=1.63 avg=2.65\n",
            "[430 | 631.81] loss=1.49 avg=2.61\n",
            "[440 | 645.96] loss=0.99 avg=2.57\n",
            "[450 | 660.12] loss=1.12 avg=2.53\n",
            "[460 | 674.29] loss=1.09 avg=2.49\n",
            "[470 | 688.46] loss=1.49 avg=2.46\n",
            "[480 | 702.62] loss=1.68 avg=2.44\n",
            "[490 | 716.77] loss=1.64 avg=2.42\n",
            "[500 | 730.93] loss=1.23 avg=2.39\n",
            "[510 | 745.09] loss=0.95 avg=2.36\n",
            "[520 | 759.24] loss=1.28 avg=2.33\n",
            "[530 | 773.40] loss=0.74 avg=2.29\n",
            "[540 | 787.55] loss=1.13 avg=2.26\n",
            "[550 | 801.70] loss=0.48 avg=2.22\n",
            "[560 | 815.85] loss=0.78 avg=2.19\n",
            "[570 | 830.02] loss=0.67 avg=2.15\n",
            "[580 | 844.18] loss=0.75 avg=2.12\n",
            "[590 | 858.33] loss=0.71 avg=2.09\n",
            "[600 | 872.48] loss=0.50 avg=2.05\n",
            "======== SAMPLE 1 ========\n",
            "I've got one hunch, too,\" he said breathlessly in the moon-splashed city-voice. \"There's some tampering, some quirk in the way the Army trains its soldiers. They decelerate the Frankins a lot, and that's something we can't fix, especially when they've got atomic weapons under control.\" As if oblivious to Alaia's insight, Raimu's eyes narrowed. \"Suppose we let Alaia go to the brig?\" Undoubtedly, they knew the guards would consider her a trespasser. But involuntary thrusts of against the rocky outcrop were something different in Alaia's case. She had never felt this way before, and they would certainly regard her as something of a trespasser. A slight menace, perhaps, but for ten thousand years she had been a free-for-all -- free-woman, her only child, free of the brutal Japanese rule of female emancipation. And although Alaia had been brutal toward the black citizens of the city, they had her by their side, and they would respect that, too. Fate had intervened somehow. Alaia had come within easy reach of her cell door when the door swung into action. Sahl had had the door closed but not yet passed the threshold of absorption into his consciousness stream. Alaia's explanation was cogent. She had not been a trespasser. Alaia's explanation was based solely on instinct. She had taken no chances. She had been struck by lightning several times before, under strikingly similar circumstances. It seemed the lightning had been drawn from beyond her window-face, and in that instant been out. Faron had stolen only a brief moment of unreasoning amusement from the situation. Then, snatching Sahl and his companion aside, he returned the door slowly. Circumstances permitted him to insert a pistol into its place. \"Supposed to be a good idea,\" he said, without apparent emotion. Alaia's explanation was even more cogent. She had merely awakened her automatic while still behind in the apartment, had suddenly stopped to look out over the garden. Faron had returned the weapon and observed the immediate emergence of a male as the female whirled to attention. \"Well, Sahl, we want you to examine the weapon. Is it a blue or brown steel shell?\" She asked in what sounded like a low voice. \"As you can see, it has a smooth bore\" Faron continued. \"And for what purpose?\" the woman asked in a faint but genuine mumble.  The question attracted no response : the bearing was obviously wasted. \"I think the big question is this: is it possible that the child is actually dead?\" The female was still quite interested in the very first suggestion of curiosity. \"Certainly,\" he agreed, \"but it's just a question of position. Can you see the big ole birdby?' \"I can,\" said Sahl. She gave him a look of utter bewilderment and then paused, obviously indicating a doorway. \"Well, how does it look in tin\". The biologist gave her a look of utter incredulity. \"What makes it ?\" \"A coronA look, at an am  flock of five or six. And ff world title. I think 'the coronA is coCello -- is it not?\" \"Coel .A'ing Rome I don't know,\" the biologist persisted. \"Or any other city on Earth.\" Her tone perestrotted, and her voice was distant and husky. \"Maybe it is. No, I'd only like to stay here a while. See you in the near future. Fm sorry for you, darling. There isn't time.\" She paused, obviously thinking of Faron. \"Tomorrow we'll see you. Later, all at once.\" As she spoke, the biologist was almost literally talking in her sleep. She had reached the twilight region of her personality, and she was still at that of the Cora man. She was not, as far as was presently possible for her true feelings. feelings, but she did not regard them feelings as being irrational or non-existent. Her real feelings were of the World of her childhood, and all too clearly expressed by the expression on her face when she was a babe. \"Tomorrow we'll see you,\" she said, and presently she made no protest. \"May I remind you of a special favour?\" \"You're invited to become my guest lecturer.\" \"May I . tell you a little bit more about it?\" \"No,\" said Faron. \"But first, I think it would be very interesting to have a closer look at this strange thing called furniture. Did you know that it's based on bacteria found in insects?\" \"Oh, not in bugs. In fact, living stags are difficult to get hold of. So we made a mechanical vac-up enclosure, as you call it, for ourselves.\" \"So you have something of a scientific bent.\"  \"Not really. I used\n",
            "\n",
            "[610 | 895.36] loss=0.41 avg=2.02\n",
            "[620 | 909.52] loss=0.67 avg=1.99\n",
            "[630 | 923.67] loss=0.66 avg=1.96\n",
            "[640 | 937.83] loss=0.47 avg=1.93\n",
            "[650 | 951.98] loss=0.48 avg=1.90\n",
            "[660 | 966.13] loss=0.57 avg=1.87\n",
            "[670 | 980.29] loss=0.40 avg=1.84\n",
            "[680 | 994.45] loss=0.34 avg=1.81\n",
            "[690 | 1008.60] loss=0.37 avg=1.78\n",
            "[700 | 1022.76] loss=0.26 avg=1.75\n",
            "[710 | 1036.91] loss=0.35 avg=1.72\n",
            "[720 | 1051.07] loss=0.27 avg=1.70\n",
            "[730 | 1065.22] loss=0.32 avg=1.67\n",
            "[740 | 1079.38] loss=0.30 avg=1.64\n",
            "[750 | 1093.53] loss=0.25 avg=1.62\n",
            "[760 | 1107.69] loss=0.20 avg=1.59\n",
            "[770 | 1121.85] loss=0.27 avg=1.57\n",
            "[780 | 1136.02] loss=0.28 avg=1.54\n",
            "[790 | 1150.21] loss=0.24 avg=1.52\n",
            "[800 | 1164.38] loss=0.35 avg=1.50\n",
            "======== SAMPLE 1 ========\n",
            " have been reduced to a small pool of molten rock with a diameter of at least three times that of Earth. In this manner, the planets are uninhabited, the atmosphereless, with electrically conductive surfaces. As the quavering steel of the planetron continues to glow, the atmosphere of the neighboring star grows in diameter, swelling and shrinking as the distance from the planetrise to at least four hundred light years. As this process continues, the atmosphere of the planet begins to thin, weakening and discarding the organic molecules that are required for life to start anew in the cosmos. As the carbonate in the atmosphere declines, the proteins that supply life begin to lose potency, and the cellular structures that carry out the chemical reactions that take place elsewhere in the body cease to function. viewed from a height of at least twelve hundred miles The mechanism apparently found in Mars is opaque, since the mineral itself is classified as non-organic by the First Amendment. But the words \"organic by reason,\" have no practical meaning except as a verb. The Martian people have always felt this way, since they saw that the Creator intended them to be non-organic by birth. The language they have learned from him is as though they had been dropped into a bucket of soap bubbles, and the solution would forever linger in their noses. But the mechanism would still give them a frightful idea, and they would flee to their own planet, destroy their neighbor, and try to breed like wild lambs in the same way. The Amalek sheep would not attack their neighbors, and they would breed as though they had not eaten for twenty-four hours. Since nothing fears Weber's law more than the idea of allowing his animals to die -- which brings us to the point -- then the cannibalism claim is hopeless. Actually most of the animals killed were of the various animals our forebears brought with them from Earth. Just as so-called \"famine transactions\" are traced back to the Egyptians, so our own own race also brought its animals with it from Earth. The earliest records of eating beef come from the earliest reports of art from the first reports of bricklayers from the first reports of factory workers from the first to be able to trace the exact origins of these trade in exhibiting our stuff. And the first reports of eating furs, or rather, the furs brought with them from Earth, are so scant in evidence that we can't be sure that the claim that our fur was brought with us from Earth is really a lie. There certainly isn't any such thing as a fur cat from Earth, and we're not going to make our own if we want our animals. There is an endless supply of fur from Earth whicli are hand-drawn on to our globe and sold for fins and feathers. We can't expect our furs to be of the same type as those brought with us from Earth. And if we don't prove the claim that our fur is of the same type as the genuine fur brought from Earth, we'll only go too far in equating our products with genuine fur. If we can prove furs exist and of a higher grade than those brought with us from Earth, we can show that we have the highest quality furs. Of course we'd need microscopes to see those specks. And the glasses we have would have to be superior lenses because those are made of lead. All in all, I would say that our work with furists is a very good example of the application of experimentation to the scientific field. If we can prove furs exist and of a higher grade than those brought from Earth, we can show that we have the highest quality furs. Of course we'd have to be able to see that they do. If we can do that -- if we can show that we have the best possible substitute for bone and fur -- then we've done something which will be a thing of beauty for the future. \" -- Charles V. Eissel, Esq.\" As I finished speaking, a door opened beneath me, and the silent giant gave a single sound-SOUND. \"Wha -- \" Charles went on ahead, and we walked out of the building. Perhaps I should have told you that the Frank Bucks Museum contained priceless t units? The sound of their footsteps drew them to the first loyer. I beckoned them to follow me, and they complied. The hall was large and ornate, with some of the best cerci of all because of its wide spread flooring. The only sound created by the ceri ter was the squeaking of the chairs being picked up abruptly by the wads of bookshelves. In this particularly sprightly room there were no books in the glimmering corner we had visited so far. A t the end of the day, we  were going to Tibet. I had been told beforehand that the Jamestown scandal was already under way and that there would be no turning back. And I should have beengrudgingly acquired the benefit of hindsight.\n",
            "\n",
            "[810 | 1187.17] loss=0.23 avg=1.48\n",
            "[820 | 1201.33] loss=0.18 avg=1.45\n",
            "[830 | 1215.50] loss=0.12 avg=1.43\n",
            "[840 | 1229.66] loss=0.25 avg=1.41\n",
            "[850 | 1243.84] loss=0.25 avg=1.39\n",
            "[860 | 1258.01] loss=0.18 avg=1.37\n",
            "[870 | 1272.18] loss=0.18 avg=1.35\n",
            "[880 | 1286.33] loss=0.20 avg=1.33\n",
            "[890 | 1300.49] loss=0.17 avg=1.31\n",
            "[900 | 1314.64] loss=0.17 avg=1.29\n",
            "[910 | 1328.80] loss=0.18 avg=1.27\n",
            "[920 | 1342.95] loss=0.12 avg=1.25\n",
            "[930 | 1357.11] loss=0.22 avg=1.23\n",
            "[940 | 1371.26] loss=0.17 avg=1.22\n",
            "[950 | 1385.42] loss=0.13 avg=1.20\n",
            "[960 | 1399.58] loss=0.12 avg=1.18\n",
            "[970 | 1413.73] loss=0.18 avg=1.17\n",
            "[980 | 1427.89] loss=0.17 avg=1.15\n",
            "[990 | 1442.05] loss=0.15 avg=1.13\n",
            "[1000 | 1456.21] loss=0.13 avg=1.12\n",
            "Saving checkpoint/scifi_f/model-1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_simple.copy_checkpoint_to_gdrive(run_name='scifi_f')"
      ],
      "metadata": {
        "id": "po46W7Q7gwDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_scifi(path):\n",
        "  gpt2_simple.generate(sess, run_name='scifi_f',prefix=path,length=250)"
      ],
      "metadata": {
        "id": "3jUeqealgnQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_scifi(\"woman in black shirt and pink shorts is sitting on bench outside my door\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQHcyqeLg2-e",
        "outputId": "2d64e6d4-43dc-4f5d-e096-00b4039f2b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woman in black shirt and pink shorts is sitting on bench outside my door. I put on my cigar and keep the cigar in one hand and the letter on the other. Finally, Steiner comes through the door. \"Hello,\" he says. \"What is it?' \"I've got it,\" I say. He smiles. \"Just figured it out, played it, told me his story.\" He speaks with a low whisper, to thrill me. He put his cigar stoically in one hand and his lip a slight bit loose with a grin. He seemed very real and all right, to the very plain and just. I keep my cigar locked in my other hand, and I keep thinking: What an experience that has been! Have they all the rules and regulations we have not yet! What an adventure! How wonderful! His stories are wonderful and I love the comity he has developed with us. I put the letter down easily, write a couple of words about the trip and come out of the hotel feeling very, very, welcome. Later on, as I'm getting closer to my first coffee break, I realize that I almost wrote the entire letter penned and typed out in a big red Sharp just like yours. I took it down easily enough, put it away easily enough, and left it in\n"
          ]
        }
      ]
    }
  ]
}